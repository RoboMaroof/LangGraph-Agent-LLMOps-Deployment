# ğŸ§  LangGraph Agent API

A modular, production-ready backend for building intelligent agent workflows using LangGraph, FastAPI, Qdrant, and Poetry â€” all containerized via Docker. This system supports vector-based document retrieval, tool-augmented LLM responses, and seamless integration with local/S3 sources.

---

## ğŸš€ Features

- âœ… Conversational agents with LangGraph + LangChain
- âœ… Tool-augmented LLM responses (Wikipedia, Arxiv, Tavily, Vector DB)
- âœ… Qdrant vector database integration
- âœ… Upload or ingest documents from S3, SQLite, or websites
- âœ… Session-based memory & history
- âœ… FastAPI REST API
- âœ… Fully containerized (Docker + Poetry)
- âœ… Modular, extensible, and ready for production

---

## ğŸ“ Project Structure

```plaintext
â”œâ”€â”€ app.py           
â”œâ”€â”€ agents/
â”‚ â”œâ”€â”€ routes.py         
â”‚ â”œâ”€â”€ agent_loader.py  
â”‚ â”œâ”€â”€ graph_builder.py          
â”‚ â””â”€â”€ tools.py  
â”œâ”€â”€ ingestion/
â”‚ â”œâ”€â”€ routes.py         
â”‚ â”œâ”€â”€ upload_handler.py  
â”‚ â”œâ”€â”€ index_builder.py       
â”‚ â””â”€â”€ sources.py   
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ config.py 
â”‚ â”œâ”€â”€ logging_config.py # TODO 
â”‚ â”œâ”€â”€ qdrant_utils.py 
â”‚ â””â”€â”€ logger.py         
â”œâ”€â”€ Dockerfile          
â”œâ”€â”€ pyproject.toml      
â”œâ”€â”€ poetry.lock         
â””â”€â”€ .env                # Local 
```

---

## âš™ï¸ Prerequisites

- [Docker](https://www.docker.com/)
- [Poetry](https://python-poetry.org/) (if running outside container)
- Qdrant Cloud or local instance
- OpenAI/Groq API key

---

## ğŸ“¦ Quick Start (with Docker)

### 1. ğŸ§ª Create `.env` File

```env
QDRANT_HOST=https://your-qdrant-instance
QDRANT_API_KEY=your-api-key
QDRANT_COLLECTION=langgraph-rag-vectordb

DEFAULT_DOCS_FOLDER=./docs
SQL_DB_PATH=./faq.sqlite3

LOG_LEVEL=DEBUG
```

---

### 2. ğŸ³ Build and Run the Docker Container

```bash
# Build the image
docker build -t langgraph-agent .

# Run the container
docker run --env-file .env -p 8000:8000 langgraph-agent
```

The server will:
- Set up Qdrant collection if needed
- Ingest documents if configured
- Preload your conversational agent

---

## ğŸ“¡ API Endpoints

`ğŸ”— /agent/invoke`
```http
POST /agent/invoke
```

***Body:***
```json
{
  "input": "Summarize LangGraph",
  "model": "openai:gpt-4o-mini",
  "session_id": "user-abc"
}
```

`ğŸ“¤ /vectordb/upload`
Upload and index a document:

```http
POST /vectordb/upload
```

`ğŸ› ï¸ /vectordb/create`
Manually ingest a source:

```json
{
  "source_type": "docs",
  "source_path": "s3://your-bucket/sample.pdf"
}
```

---

## ğŸ§© Supported Source Types

| Type     | Description                         |
|----------|-------------------------------------|
| `docs`   | Local folders or S3 document files  |
| `sql`    | SQLite FAQ table (Q/A pairs)        |
| `website`| Public URLs                         |

---

## ğŸ”Œ Tools Used

| Tool              | Description                             |
|-------------------|-----------------------------------------|
| WikipediaQueryRun | Wikipedia search                        |
| ArxivQueryRun     | Arxiv academic paper search             |
| TavilySearch      | Web search via Tavily                   |
| vector_retriever  | Custom document retrieval via Qdrant   |

---